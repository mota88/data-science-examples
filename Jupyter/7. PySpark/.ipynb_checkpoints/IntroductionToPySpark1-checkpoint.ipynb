{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster('local').setAppName('Mi Programa')\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Mi Programa</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Mi Programa>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ejemplo.txt MapPartitionsRDD[1] at textFile at <unknown>:0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = sc.textFile('ejemplo.txt')\n",
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{{Infobox software'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines2 = lines.sample(fraction=0.1, withReplacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'| developer              = [[Apache Spark]]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines2.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = lines.filter(lambda line:'Python' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[5] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['| programming language   = [[Scala (programming language)|Scala]]<ref>{{cite web |url=https://spark.apache.org/releases/spark-release-2-0-0.html |title=Spark Release 2.0.0 |quote=MLlib in R: SparkR now offers MLlib APIs [..] Python: PySpark now offers many more MLlib algorithms\"}}</ref>',\n",
       " '| language               = [[Scala (programming_language)|Scala]], [[Java (programming language)|Java]], [[SQL]], [[Python (programming language)|Python]], [[R (programming language)|R]], [[C Sharp (programming language)|C#]], [[F Sharp (programming language)|F#]]',\n",
       " 'Spark Core is the foundation of the overall project. It provides distributed task dispatching, scheduling, and basic [[I/O interface|I/O]] functionalities, exposed through an application programming interface (for [[Java (programming language)|Java]], [[Python (programming language)|Python]], [[Scala (programming language)|Scala]], [[.NET Core|.NET]]<ref name=\":1\">{{Citation|title=dotnet/spark|date=2020-09-14|url=https://github.com/dotnet/spark|publisher=.NET Platform|access-date=2020-09-14}}</ref> and [[R (programming language)|R]]) centered on the RDD [[Abstraction (computer science)|abstraction]] (the Java API is available for other JVM languages, but is also usable for some other non-JVM languages that can connect to the JVM, such as [[Julia (programming language)|Julia]]<ref>{{Cite web | url=https://github.com/dfdx/Spark.jl |title =GitHub - DFDX/Spark.jl: Julia binding for Apache Spark.|date = 2019-05-24}}</ref>). This interface mirrors a [[functional programming|functional]]/[[higher-order programming|higher-order]] model of programming: a \"driver\" program invokes parallel operations such as map, [[Filter (computer science)|filter]] or reduce on an RDD by passing a function to Spark, which then schedules the function\\'s execution in parallel on the cluster.{{r|hc10}} These operations, and additional ones such as [[Join (database)|joins]], take RDDs as input and produce new RDDs. RDDs are [[Immutable object|immutable]] and their operations are [[lazy evaluation|lazy]]; fault-tolerance is achieved by keeping track of the \"lineage\" of each RDD (the sequence of operations that produced it) so that it can be reconstructed in the case of data loss. RDDs can contain any type of Python, .NET, Java, or Scala objects.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado2 = lines.filter(lambda x:any(i.isdigit() for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['| logo                   = [[File:Apache Spark logo.svg|frameless|250px|Spark Logo]]',\n",
       " '| released               = [https://github.com/apache/spark/releases/tag/v1.0.0 {{Start date and age|2014|05|26}}]',\n",
       " '| latest release version = 3.0.1']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{{Infobox software',\n",
       " '| name                   = Apache Spark',\n",
       " '| caption                = ',\n",
       " '| author                 = [[Matei Zaharia]]',\n",
       " '| developer              = [[Apache Spark]]']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.filter(lambda x:not any(i.isdigit() for i in x)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[12] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado2.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Z:/csv/casos_diagnostico_ccaa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccaa_iso</th>\n",
       "      <th>fecha</th>\n",
       "      <th>num_casos</th>\n",
       "      <th>num_casos_prueba_pcr</th>\n",
       "      <th>num_casos_prueba_test_ac</th>\n",
       "      <th>num_casos_prueba_ag</th>\n",
       "      <th>num_casos_prueba_elisa</th>\n",
       "      <th>num_casos_prueba_desconocida</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AN</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AR</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CB</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CE</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ccaa_iso       fecha  num_casos  num_casos_prueba_pcr  \\\n",
       "0       AN  2020-01-01          0                     0   \n",
       "1       AR  2020-01-01          0                     0   \n",
       "2       AS  2020-01-01          0                     0   \n",
       "3       CB  2020-01-01          0                     0   \n",
       "4       CE  2020-01-01          1                     0   \n",
       "\n",
       "   num_casos_prueba_test_ac  num_casos_prueba_ag  num_casos_prueba_elisa  \\\n",
       "0                         0                    0                       0   \n",
       "1                         0                    0                       0   \n",
       "2                         0                    0                       0   \n",
       "3                         0                    0                       0   \n",
       "4                         0                    1                       0   \n",
       "\n",
       "   num_casos_prueba_desconocida  \n",
       "0                             0  \n",
       "1                             0  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "from pyspark import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "dfspark = sqlContext.read.format('csv').option('header','true').option('inferSchema','true').load('Z:/csv/casos_diagnostico_ccaa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+--------------------+------------------------+-------------------+----------------------+----------------------------+\n",
      "|ccaa_iso|     fecha|num_casos|num_casos_prueba_pcr|num_casos_prueba_test_ac|num_casos_prueba_ag|num_casos_prueba_elisa|num_casos_prueba_desconocida|\n",
      "+--------+----------+---------+--------------------+------------------------+-------------------+----------------------+----------------------------+\n",
      "|      AN|2020-01-01|        0|                   0|                       0|                  0|                     0|                           0|\n",
      "|      AR|2020-01-01|        0|                   0|                       0|                  0|                     0|                           0|\n",
      "+--------+----------+---------+--------------------+------------------------+-------------------+----------------------+----------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfspark.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ccaa_iso='AN', fecha='2020-01-01', num_casos=0, num_casos_prueba_pcr=0, num_casos_prueba_test_ac=0, num_casos_prueba_ag=0, num_casos_prueba_elisa=0, num_casos_prueba_desconocida=0),\n",
       " Row(ccaa_iso='AR', fecha='2020-01-01', num_casos=0, num_casos_prueba_pcr=0, num_casos_prueba_test_ac=0, num_casos_prueba_ag=0, num_casos_prueba_elisa=0, num_casos_prueba_desconocida=0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7296"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfspark = dfspark.sample(fraction=0.001, withReplacement=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfspark.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = dfspark.na.drop(subset=['num_casos','num_casos_prueba_pcr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.filter('num_casos_prueba_pcr is not NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ccaa_iso: string (nullable = true)\n",
      " |-- fecha: string (nullable = true)\n",
      " |-- num_casos: integer (nullable = true)\n",
      " |-- num_casos_prueba_pcr: integer (nullable = true)\n",
      " |-- num_casos_prueba_test_ac: integer (nullable = true)\n",
      " |-- num_casos_prueba_ag: integer (nullable = true)\n",
      " |-- num_casos_prueba_elisa: integer (nullable = true)\n",
      " |-- num_casos_prueba_desconocida: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "media = np.mean(df3.select('num_casos').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.90909090909093"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
